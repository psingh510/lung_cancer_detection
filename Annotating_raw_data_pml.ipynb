{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68a8c034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c21c01b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_image(image_path):\n",
    "    \"\"\"Process a single image using the original logic.\"\"\"\n",
    "    # Read the image with unchanged flag\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "    if image is None:\n",
    "        return None, None, 0\n",
    "    \n",
    "    # Convert to 3-channel if it's single channel\n",
    "    if len(image.shape) == 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Create a new image\n",
    "    new_image = np.zeros(image.shape, image.dtype)\n",
    "    alpha = 3.5\n",
    "    beta = 0\n",
    "    \n",
    "    for y in range(image.shape[0]):\n",
    "        for x in range(image.shape[1]):\n",
    "            for c in range(image.shape[2]):\n",
    "                new_image[y,x,c] = np.clip(alpha*image[y,x,c] + beta, 0, 255)\n",
    "                \n",
    "    gray_image = cv2.cvtColor(new_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    \n",
    "    threshold = 50\n",
    "     \n",
    "    mask = gray_image > threshold\n",
    "    new_image[mask] = [0, 255, 0]  # Set to green\n",
    "    \n",
    "    # Convert to RGB for processing\n",
    "    image_rgb = cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB)\n",
    "    hsv_image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    # Define range for green color in HSV\n",
    "    lower_green = np.array([40, 40, 40])\n",
    "    upper_green = np.array([80, 255, 255])\n",
    "    green_mask = cv2.inRange(hsv_image, lower_green, upper_green)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(green_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Draw bounding squares on the original RGB image\n",
    "    annotated_image = image_rgb.copy()\n",
    "    \n",
    "    dot_info = []\n",
    "    for i, contour in enumerate(contours):\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        cv2.rectangle(annotated_image, (x, y), (x + w, y + h), (255, 255, 0), 2)\n",
    "        \n",
    "        dot_info.append({\n",
    "            'dot_id': i + 1,\n",
    "            'position': {'x': int(x + w/2), 'y': int(y + h/2)},\n",
    "            'width': w,\n",
    "            'height': h,\n",
    "            'area': int(cv2.contourArea(contour))\n",
    "        })\n",
    "    \n",
    "    # Convert back to BGR for saving\n",
    "    annotated_image_bgr = cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    return annotated_image_bgr, dot_info, len(contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f41f40ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(input_folder, output_folder, json_output_path):\n",
    "    \"\"\"Process all images in a folder and save results.\"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    results = {\n",
    "        'processing_date': datetime.now().isoformat(),\n",
    "        'total_images_processed': 0,\n",
    "        'images': {}\n",
    "    }\n",
    "    \n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith(('.tif', '.tiff')):\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "            print(f\"Processing {filename}...\")\n",
    "            \n",
    "            try:\n",
    "                annotated_image, dot_info, dot_count = process_single_image(image_path)\n",
    "                \n",
    "                if annotated_image is None:\n",
    "                    print(f\"Failed to process {filename}\")\n",
    "                    continue\n",
    "                \n",
    "                # Save the annotated image as TIFF with maximum quality\n",
    "                output_filename = os.path.join(output_folder, f\"annotated_{filename}\")\n",
    "                # Save with original bit depth and compression\n",
    "                cv2.imwrite(output_filename, \n",
    "                          annotated_image,\n",
    "                          [cv2.IMWRITE_TIFF_COMPRESSION, 1])  # Use LZW compression for better quality\n",
    "                \n",
    "                results['images'][filename] = {\n",
    "                    'filename': filename,\n",
    "                    'annotated_filename': f\"annotated_{filename}\",\n",
    "                    'dot_count': dot_count,\n",
    "                    'dots': dot_info\n",
    "                }\n",
    "                \n",
    "                results['total_images_processed'] += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    with open(json_output_path, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1873b84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing flattened_position_10_C1.tif...\n",
      "Processing flattened_position_6_C1.tif...\n",
      "Processing flattened_position_34_C1.tif...\n",
      "Processing flattened_position_26_C1.tif...\n",
      "Processing flattened_position_38_C1.tif...\n",
      "Processing flattened_position_4_C1.tif...\n",
      "Processing flattened_position_8_C1.tif...\n",
      "Processing flattened_position_12_C1.tif...\n",
      "Processing flattened_position_24_C1.tif...\n",
      "Processing flattened_position_28_C1.tif...\n",
      "Processing flattened_position_36_C1.tif...\n",
      "Processing flattened_position_32_C1.tif...\n",
      "Processing flattened_position_20_C1.tif...\n",
      "Processing flattened_position_16_C1.tif...\n",
      "Processing flattened_position_22_C1.tif...\n",
      "Processing flattened_position_30_C1.tif...\n",
      "Processing flattened_position_2_C1.tif...\n",
      "Processing flattened_position_18_C1.tif...\n",
      "Processing flattened_position_14_C1.tif...\n",
      "Processing flattened_position_35_C1.tif...\n",
      "Processing flattened_position_39_C1.tif...\n",
      "Processing flattened_position_27_C1.tif...\n",
      "Processing flattened_position_11_C1.tif...\n",
      "Processing flattened_position_7_C1.tif...\n",
      "Processing flattened_position_25_C1.tif...\n",
      "Processing flattened_position_37_C1.tif...\n",
      "Processing flattened_position_29_C1.tif...\n",
      "Processing flattened_position_5_C1.tif...\n",
      "Processing flattened_position_9_C1.tif...\n",
      "Processing flattened_position_13_C1.tif...\n",
      "Processing flattened_position_17_C1.tif...\n",
      "Processing flattened_position_1_C1.tif...\n",
      "Processing flattened_position_33_C1.tif...\n",
      "Processing flattened_position_21_C1.tif...\n",
      "Processing flattened_position_3_C1.tif...\n",
      "Processing flattened_position_19_C1.tif...\n",
      "Processing flattened_position_15_C1.tif...\n",
      "Processing flattened_position_40_C1.tif...\n",
      "Processing flattened_position_23_C1.tif...\n",
      "Processing flattened_position_31_C1.tif...\n",
      "Processed 40 images\n",
      "Results saved to /Users/pallavisingh/Library/CloudStorage/OneDrive-SharedLibraries-DalhousieUniversity/Priyadharshini Sridharan - Images from Dellaire Lab/merged_pml_images_High_Arsenic_annotations/merged_pml_images_High_Arsenic_annotations.json \n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = \"/Users/pallavisingh/Library/CloudStorage/OneDrive-SharedLibraries-DalhousieUniversity/Priyadharshini Sridharan - Images from Dellaire Lab/merged_pml_images_High_Arsenic\"  # Replace with your input folder path\n",
    "    output_folder = \"/Users/pallavisingh/Library/CloudStorage/OneDrive-SharedLibraries-DalhousieUniversity/Priyadharshini Sridharan - Images from Dellaire Lab/merged_pml_images_High_Arsenic_annotations\"  # Replace with your output folder path\n",
    "    json_output_path = \"/Users/pallavisingh/Library/CloudStorage/OneDrive-SharedLibraries-DalhousieUniversity/Priyadharshini Sridharan - Images from Dellaire Lab/merged_pml_images_High_Arsenic_annotations/merged_pml_images_High_Arsenic_annotations.json \"\n",
    "    \n",
    "    results = process_folder(input_folder, output_folder, json_output_path)\n",
    "    print(f\"Processed {results['total_images_processed']} images\")\n",
    "    print(f\"Results saved to {json_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f486d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
